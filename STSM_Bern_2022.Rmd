---
title: "Ro Covid-19 credits spacetime analysis"
output:
  html_notebook: default
  pdf_document: default
---
## Setup
Import libraries. 

```{r}
library(sp)
library(rgdal)
library(broom)
library(rgeos)
library(splm)
library(spdep) #useful to turn a W matrix into a list w matrix
library(texreg)
library(pder)
library(spatialreg)
library(spData)
library(ggplot2)
library(zeallot)
```
Read the dataset (non-spatial one):
```{r}
ro_Vaccines_incidence_socioec <- read.csv(file = 'data/ro_Vaccines_incidence_socioec.csv')
head(ro_Vaccines_incidence_socioec)
```
Rename columns:
```{r}
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[1]] <- 'empl'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[2]] <- 'living_spa'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[3]] <- 'vote'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[4]] <- 'airp'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[5]] <- 'prim_edu'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[6]] <- 'elder'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[7]] <- 'pover'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[8]] <- 'neoprot'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[9]] <- 'migr_exp'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[10]] <- 'cov_max'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[11]] <- 'core_c'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[12]] <- 'per_c'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[13]] <- 'per_v'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[14]] <- 'size'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[15]] <- 'sch_enrol'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[16]] <- 'vaccR_Oct'
names(ro_Vaccines_incidence_socioec)[names(ro_Vaccines_incidence_socioec) == colnames(ro_Vaccines_incidence_socioec)[18]] <- 'vaccR_May'
```

```{r}
head(ro_Vaccines_incidence_socioec)
```
Standardize using z-score all variables except the dummy ones:
```{r}
ro_Vaccines_incidence_socioec_std <-  as.data.frame(scale(ro_Vaccines_incidence_socioec, center = TRUE, scale = TRUE))
ro_Vaccines_incidence_socioec_std$siruta <- ro_Vaccines_incidence_socioec$siruta
ro_Vaccines_incidence_socioec_std$core_c <- ro_Vaccines_incidence_socioec$core_c
ro_Vaccines_incidence_socioec_std$per_c <- ro_Vaccines_incidence_socioec$per_c
ro_Vaccines_incidence_socioec_std$per_v <- ro_Vaccines_incidence_socioec$per_v
ro_Vaccines_incidence_socioec_std$airp <- ro_Vaccines_incidence_socioec$airp
ro_Vaccines_incidence_socioec_std$size <- ro_Vaccines_incidence_socioec$size

head(ro_Vaccines_incidence_socioec_std)
```
Get summary statistics:
```{r}
summary(ro_Vaccines_incidence_socioec_std)
```
```{r}
write.csv(ro_Vaccines_incidence_socioec_std,"ro_Vaccines_incidence_socioec_std.csv", row.names = FALSE)
```

Turn off scientific notations for resonably sized values:
```{r}
options(scipen=7)
```
Read the shapefile with the polygons for each TAU and construct the spatial weights matrix.
```{r}
ro_atu <- readOGR('data/ro_atu.shp')
coordinates <- coordinates(ro_atu)
ro_atu
```
## Analyze and create spatial weights matrices
### Queen
```{r}
# read the row-standardized W matrix
queen <- poly2nb(ro_atu, queen=TRUE)
summary(queen) # same as what you would compute in Geoda for queen order 1 (no row standardization)
```
```{r}
str(queen[1:5]) #visualize the first 5 entries
```
Each element of the list shows the neighbors of each spatial unit.
To get the centroids of each spatial unit:
```{r}

```

```{r}
queen[[3]] #calling one vector from the nb matrix
length(queen[[3]])
queen[[3]][1] #first element of the vector
w_queen <- nb2mat(queen) # outputs a row-standardized matrix 'W'
w_queen[1:5]
rowSums(w_queen)[1:5] #compute the sum of rows
```
To compute a binary matrix (0=no neighbor, 1=neighbor):
```{r}
w2_queen <- w_queen
w2_queen[w2_queen>0]<-1 #replace all values that are grated than 0 with 1 (this will generate a binary matrix 'B')
w2_queen[1:5]
rowSums(w2_queen)[1:5] # the sum of the rows will be the sum of each unit's neighbors
```
```{r}
w_queen <- nb2listw(queen, style='W') # outputs a row-standardized list matrix 'W'
summary(w_queen)
```
Alternatively, the spatial weights matrix can be computed in geoda and used here:
```{r}
w_queen <- read.gal("data/queen_1ord_symmetric.gal")  # same as above but computed in Geoda for queen order 1 (no row standardization)
w_queen <- nb2listw(w_queen, style='W')
summary(w_queen)
```
Yields the same results in the spatial modeling phase.
### Distance based
First, compute the centroids of the polygons:
```{r}
coords <- coordinates(ro_atu)
head(coords)
```
To compute a distance-based matrix we can treat the ATUs as points using their centroids:
```{r}
#in general W is a function of the pairwise distance between observations
str(dist(coordinates)) #euclidean distance between points
distM<- as.matrix(dist(coordinates))
str(distM)
round(distM[1:5,1:5],3)
```
```{r}
w_dist<- 1/(distM) #inverse of the distance matrix
w_dist[1:5]
W2<- 1/(1+distM)^2 #inverse power of the distance matrix
W3<- exp(-distM^2) #negative exponential distance matrix 
diag(w_dist) <- 0 #assign 0 to diagonal
diag(W2) <- 0 
diag(W3) <- 0
```
Row standardize the distance based matrix
```{r}
w_dist_rstd <- dist/rowSums(w_dist) #row-standardization (in case of zeroes, a different formula should be used to avoid division by 0)
w_dist_rstd[1:5]
```
```{r}
w_dist_rstd <- mat2listw(w_dist_rstd) #convert to listw
summary(w_dist_rstd)
```
Min-max standardization (Kelejian and Prucha):
```{r}
cc<- min(max(rowSums(w_dist)),max(colSums(w_dist)))
w_dist_2<-w_dist/cc
w_dist_2[1:5] #not useful
```
Check if matrix is row-standardized
```{r}
unique(rowSums(w_dist_rstd))
```
### KNN
Neighborhood based on the k-nearest neighborhood criterion
```{r}
str(knearneigh(coordinates,k=10))
w_knn<- knn2nb(knearneigh(coordinates,k=10))
str(w_knn[1:5])
W_knn<- nb2mat(w_knn)
unique(rowSums(W_knn))
```
Neighborhood based on the cut-off distance (consequences: number of neighbors is not constant, and: there might also be some isolated points, hence islands or no neighbors)
```{r}
cf<- quantile(distM, prob=0.05) #5% quantile
cutoff_nb<- dnearneigh(coordinates,0,cf)
# W_cf is row-std and usually not symmetric
W_cf <- nb2mat(cutoff_nb,zero.policy = TRUE)
unique(rowSums(W_cf))
```
## Spatial model selection
```{r}
regr_fm <- vaccR_May~pover+elder+prim_edu+empl+migr_exp+vote+neoprot+living_spa+airp+cov_max+size+core_c+per_c+per_v
olsmod <- lm(regr_fm, ro_Vaccines_incidence_socioec_std) # simple OLS model
summary(olsmod)
```

Compute the Moran index for the OLS residuals
```{r}
lm.morantest(olsmod, w_queen)
```
```{r}
library(olsrr)
ols_test_breusch_pagan(olsmod, rhs=TRUE, multiple=TRUE)
```
```{r}
ols_test_normality(olsmod)
```
```{r}
ols_test_correlation(olsmod)
```
Compute the spatial diagnosis to see which spatial effect to take into consideration:
*LMlag:* test for spatial lag assuming there is no spatial error (uses the residuals of the ols)
*LMerr:* tests for the spatial error assuming there is no spatial lag (uses the residuals of the ols)
The robust tests (introduced in '93 by Anil Bera, is robust up to one point) are actually locally robust (looking for a moderate level of spatial dependence), they are based on accounting for non-gigantic deviations from the null effect.
*RLMlag:* tests for the spatial lag with respect to the spatial error (uses the residuals of the spatial error model)
*RLMerr:* tests for the spatial error with respect to the spatial lag (uses the residuals of the spatial lag model)
Anselin would suggest to pick the model that has a lower p value
```{r}
lm.LMtests(olsmod, w_queen, test='all')
```
The values of the tests non-robust form were strongly affected by the presence of the other effect (high values), while in the robust form the values are low.   
CONCLUSION: *The most appropriate direction in which to look for spatial effects would be the spatial error in combination with a spatial lag.*  

Let's compute the SLX model (spatially lagged Xs) 
$y=X\beta+WX\theta+\epsilon$

```{r}
slxmod <- lmSLX(regr_fm, ro_Vaccines_incidence_socioec_std, w_queen)
summary(slxmod)
```
The sLX model gives two sets of slopes, one for the own(direct) effects and one for the neighbor(indirect) effects. By simply adding them, you can get the total marginal effects.  
To manually compute the R-squared value (as there used to be a bug in the SLX)
```{r}
rsq.slxmod <- 1-sum(slxmod$residuals^2)/(var(ro_Vaccines_incidence_socioec_std$vaccR_May))*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)
rsq.slxmod
```
Same for ols:
```{r}
rsq.olsmod <- 1-sum(olsmod$residuals^2)/(var(ro_Vaccines_incidence_socioec_std$vaccR_May))*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)
rsq.olsmod #looks good doesn't work
```

So far, the lagged coefficients are representative for the indirect effects while the regular ones are for the direct effects. To compute the marginal effects, direct, indirect and total (to also account for the significance of the results):
```{r}
summary(impacts(slxmod, listw=w_queen), zstats=TRUE)
```
Alternatively, we can compute it for some independent variables only, the ones that make sense:
```{r}
x <- model.matrix(regr_fm)
lagx <- create_WX(x, w_queen, prefix="laxx")
ro_Vaccines_incidence_socioec2 <- cbind(ro_Vaccines_incidence_socioec_std, lagx)
regr_lagx_fm <- lm(vaccR_May~pover+elder+prim_edu+empl+migr_exp+vote+neoprot+living_spa+airp+cov_max+size+core_c+per_c+per_v+
                     lagx.pover+lagx.prim_edu, lagx.empl, lagx.airp, lagx.cov_max)
summary(regr_lagx_fm) #looks good doesn't work
```
Let's compute the SAR model (spatial lag model or global spatial model) 
$y=\rho Wy+X\beta+\epsilon$

```{r}
sarmod <- lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_queen)
summary(sarmod)
```
Rho is the spatial lag parameter (of the dependent variable) and it tells us to what degree the neighbor values of y affect the own values of y. The slope estimates (values of the coefficients) are not relevant for interpretation in this case, because of the global feedback effect given by the spatial lag of the dependent variable. Rather look at the marginal effects:
```{r}
summary(impacts(sarmod, listw=w_queen, R=999), zstats=TRUE) #R is for permutations
```
Let's compute the SER model (spatial error model) 
$y=X\beta+u$, $u=\lambda Wu+\epsilon$
```{r}
sermod <- errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_queen)
summary(sermod)
```
The lambda parameter tells us if there is a stochastic shock in the neighbors how does it affect the value of our stochastic error term.
In this case, the coefficients can be interpreted as marginal effects. The significant lambda tells us that the residuals are non-random (a form of spatial heteroskedasticity or spatial autocorrelation).

The spatial Hausman test - looks and compares the parameters estimates of two models: OLS and SEM - sets the structure of spatial noise in the residual term == a form of spatial heteroskedasticity or spatial autocorrelation (classical:  see if I leave out the fixed effects parameters does it biases the coefficient estimates). The test says that the parameter estimates should not be too different, if they are (significant difference between the parameter estimates of the two models), neither of the two models is correct -> as we do have some spatial dependence and the SEM is not the correct model to capture the spatial results.
```{r}
Hausman.test(sermod)
```
The test tells us that neither the OLS nor the SEM is the right model to capture these coefficients. Another model should be explored.

Elhorst: Start with a general model and get to more specific models, then compute the log-likelihood test LM (Lagrange Multiplier) or the Moran test on the residuals. This is referred by the term: nested models, the most general being the Manski Model (usually not recommended):  
$y=\rho Wy+X\beta+WX\theta+u$, $u=\lambda Wu+\epsilon$  
with its simplified forms:  
1. when $\theta=0$ Kelejan-Prucha, SARAR, SAC, Cliff-Ord model, when $y=\rho$ SER, when $\lambda=0$ Spatial Lag, Lag Y, SAR model, and further simplified to OLS  
2. when $\lambda=0$ Spatial Durbin Model model, when $\rho=0$ Spatially Lagged X (SLX), when $\theta=0$ Spatial Lag, Lag Y, SAR model, $\theta=-\rho\beta$ SEM model, and further simplified to OLS  
3. when $\rho=0$ Spatial Durbin Error Model, when $\theta=0$ SEM model, when $\lambda=0$ SLX, and further simplified to OLS
LeSage (2014) encourages to start with SDM (for global relationships -has the lagged Y- in your model: if sth happens in one region, the impact will spillover to every region in the dataset because of the spatially lagged Y, as it will allow the propagation of that event in every region even not in the neghborhood) or SDEM (for local relationships).

The Manski model:
```{r}
manmod=sacsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, queen_l, type="sacmixed") # a different weights matrix can be specified for the error structure if desired, using the {listw2=,} parameter
summary(manmod)
```
Tidy coefficients and automatically write a csv file with them:
```{r}
tidy_manmod <- tidy(manmod)
write.csv(tidy_manmod, "data/tidy_manmod.csv")
```
The SARAR model(Kelejan-Prucha Model, Cliff-Ord or SAC Model):
$y=\rho Wy+X\beta+u$, $u=\lambda Wu+\epsilon$ 
```{r}
sararmod=sacsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, queen_l, type="sac")
summary(sararmod)
```
As per Anselin's LM tests, the SARAR model should be computed as well. However, the model cannot be (yet) computed in R, nor does Anselin advise starting with this model. Best is to just include the test for SARMA for completeness.

Using the same W matrix for lag and error terms can lead to identification problems. Probably best to avoid these models. HOWEVER, sometimes people mention a SARMA(p,q), allowing for p different 𝜌𝑊𝑦 W matrices, and q different 𝜃𝑊𝜀 terms likewise (normally W’s of different orders)

The SDEM (Spatial Error Durbin Model->adds lag X to SEM):
$y=X\beta +WX\theta +u$, $u=\lambda Wu+\epsilon$ 
```{r}
sdemmod = errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_queen, etype='emixed')
summary(sdemmod)
```
```{r}
lm.morantest(sdemmod, w_queen)
```

Lambda is the multiplier on the residuals (covers the unexplained).
Compute the direct and indirect effects for the SDEM model:
```{r}
summary(impacts(sdemmod, listw=w_queen, R=999), zstats=TRUE) #R is for permutations
```
The total effect is different than the simple sum of indirect and direct effects in this case (contrasting with what happens in the SLX model), as it also includes the error lag structure. 
The SDM (Spatial Durbin Model <- adds lag X to SAR):
$y=\rho Wy+X\beta+WX\theta+\epsilon$ 
```{r}
sdmmod = lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_queen, type='mixed')
summary(sdmmod)
```
```{r}
summary(impacts(sdmmod, listw=w_queen, R=999), zstats=TRUE) #R is for permutations
```
Compute the likelihood ratio test (only tests restriction to a simpler, more restricted, nested model) to see if SDEM should be restricted to the SEM(drop the lagged Xs) or to a SLX(drop the lagged error). Ho:restrictions are true==we should restrict the model to something simpler. SDM and SDEM are not nested, as one cannot be simplified into the other.
```{r}
LR.Sarlm(sdemmod, sermod) # order of models is not important
LR.Sarlm(sdemmod, slxmod)
```


The df (degrees of freedom) suggest how many things we're restricting, in this case 14 WXs. The null hypothesis is rejected here, the model shouldn't be restriced to SEM.
One df as there is just the spatially lagged error which is restricted (=0). Again, we shouldn't restrict the model to an SLX one. Therefore, we shouldn't restrict it even further to an OLS model.
```{r}
LR.Sarlm(sdmmod, sermod)
LR.Sarlm(sdmmod, slxmod)
```
To compare between the SDEM and SDM there are some Bayesian methods that could be used (the J test) (Kelejan 2008) -maybe not possible in R.
Further testing of the model includes to check whether there is heteroskedasticity-is not affecting the coefficients, but it affects the p-values and the standard errors, probably not much- in the model (using the studentized Breusch-Pagan test).

```{r}
bptest.Sarlm(sdemmod, studentize=TRUE)
```

Heteroscedasticity is present as per the alternative hypothesis, meaning that the residuals are not distributed with equal variance. However, due to the extremely low p-values, it is not likely that the heteroskedasticity affects the results.  
Another goodness of fit measure for the model is the pseudo R squared (what percentage of the variation the spatial model is predicting).
```{r}
1-(sdemmod$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_May)*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)))
```

74% of the variation of the Y variable is explained(=accounted for) by the model.
```{r}
for (model in list(list(slxmod, 'slxmod'), list(sarmod,'sarmod'), list(sermod, 'sermod'), list(sdmmod,'sdmmod'), list(sdemmod, 'sdemmod'))) {
  c(model_obj, model_string)%<-%model
  tidy_model <- tidy(model_obj)
  write.csv(tidy_model, sprintf("data/tidy_%s.csv", model_string))

}
```
## Running the same models using other W matrices

```{r}
w_queen2 <- read.gal("data/queen_2ord_symmetric.gal")
w_queen2 <- nb2listw(w_queen2, style='W')
summary(w_queen2)
```


```{r}
lm.morantest(olsmod, w_queen2)
lm.LMtests(olsmod, w_queen2, test='all')
```

```{r}
slxmod2 <- lmSLX(regr_fm, ro_Vaccines_incidence_socioec, w_queen2)
summary(slxmod2)
```


```{r}
summary(impacts(slxmod2, listw=w_queen), zstats=TRUE)
```

```{r}
sarmod2 <- lagsarlm(regr_fm, ro_Vaccines_incidence_socioec, w_queen2)
summary(sarmod2)
summary(impacts(sarmod2, listw=w_queen, R=999), zstats=TRUE)
```


```{r}
sermod2 <- errorsarlm(regr_fm, ro_Vaccines_incidence_socioec, w_queen2)
summary(sermod2)
Hausman.test(sermod2)
```


```{r}
sdemmod2 = errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_queen2, etype='emixed')
summary(sdemmod2)
summary(impacts(sdemmod2, listw=w_queen, R=999), zstats=TRUE)
``` 

```{r}
LR.Sarlm(sdemmod2, sermod2)
LR.Sarlm(sdemmod2, slxmod2)
``` 

```{r}
bptest.Sarlm(sdemmod2, studentize=TRUE)
1-(sdemmod2$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_May)*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)))
``` 

```{r}
sdmmod2 = lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_queen2, type='mixed')
summary(sdmmod2)
``` 

Tidy coefficients and automatically write a csv file with them:
```{r}
for (model in list(list(slxmod2, 'slxmod2'), list(sarmod2,'sarmod2'), list(sermod2, 'sermod2'), list(sdmmod2,'sdmmod2'), list(sdemmod2, 'sdemmod2'))) {
  c(model_obj, model_string)%<-%model
  tidy_model <- tidy(model_obj)
  write.csv(tidy_model, sprintf("data/tidy_%s.csv", model_string))

}
```

#### Distance matrix
```{r}
w_dist2 <- read.gal("data/distance_4000euclid_symmetric.gal")
w_dist2 <- nb2listw(w_dist2, style='W')
summary(w_dist2)
```
```{r}
lm.morantest(olsmod, w_dist2)
lm.LMtests(olsmod, w_dist2, test='all')
``` 

```{r}
slxmod3 <- lmSLX(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist2)
summary(slxmod3)
```

```{r}
summary(impacts(slxmod3, listw=w_dist2), zstats=TRUE)
``` 

```{r}
sarmod3 <- lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist2)
summary(sarmod3)
summary(impacts(sarmod3, listw=w_dist2, R=999), zstats=TRUE)
```

```{r}
sermod3 <- errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist2)
summary(sermod3)
```

```{r}
Hausman.test(sermod3)
``` 

```{r}
sdmmod3 = lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist2, type='mixed')
summary(sdmmod3)
summary(impacts(sdmmod2, listw=w_dist2, R=999), zstats=TRUE)
```
```{r}
sdemmod3 = errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist2, etype='emixed')
summary(sdemmod3)
summary(impacts(sdemmod3, listw=w_dist2, R=999), zstats=TRUE)
```

```{r}
LR.Sarlm(sdemmod3, sermod3)
LR.Sarlm(sdemmod3, slxmod3)

bptest.Sarlm(sdemmod3, studentize=TRUE)
1-(sdemmod3$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_May)*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)))
```

Conclusions (comparison with queen ord 1):  
* global moran on ols residuals is lower, still highly significant -> models need to be respecified. Anselin's LM tests are all highly significant, with much higher values than when queen matrix was used.  
* Hausman on SEM is not significant, hence the model can be estimated as a SEM - is the correct model to capture the spatial results (as we do not have some spatial dependence)  
* Heteroscedasticity is present as per the alternative hypothesis, meaning that the residuals are not distributed with equal variance. However, due to the extremely low p-values, it is not likely that the heteroskedasticity affects the results. (same as in the case of queen order 1)  
* Pseudo R squared: 69% (74% with queen order 1) of the variation of the Y variable is explained by the model.  

Tidy coefficients and automatically write a csv file with them:
```{r}
for (model in list(list(slxmod3, 'slxmod3'), list(sarmod3,'sarmod3'), list(sermod3, 'sermod3'), list(sdmmod3,'sdmmod3'), list(sdemmod3, 'sdemmod3'))) {
  c(model_obj, model_string)%<-%model
  tidy_model <- tidy(model_obj)
  write.csv(tidy_model, sprintf("data/tidy_%s.csv", model_string))
}
```

```{r}
w_dist3 <- read.gal("data/distance_25000euclid_symmetric.gal")
w_dist3 <- nb2listw(w_dist3, style='W')
lm.morantest(olsmod, w_dist3)
#lm.LMtests(olsmod, w_dist3, test='all')
slxmod4 <- lmSLX(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist3)
summary(slxmod4)
sarmod4 <- lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist3)
summary(sarmod4)
sermod4 <- errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist3)
summary(sermod4)
Hausman.test(sermod4)
sdmmod4 = lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist3, type='mixed')
summary(sdmmod4)
sdemmod4 = errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist3, etype='emixed')
summary(sdemmod4)
LR.Sarlm(sdemmod4, sermod4)
LR.Sarlm(sdemmod4, slxmod4)
bptest.Sarlm(sdemmod4, studentize=TRUE)
1-(sdemmod4$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_May)*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)))
```


```{r}
w_dist4 <- read.gal("data/distance_30000euclid_symmetric.gal")
w_dist4 <- nb2listw(w_dist4, style='W')
lm.morantest(olsmod, w_dist4)
#lm.LMtests(olsmod, w_dist4, test='all')
slxmod5 <- lmSLX(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist4)
summary(slxmod5)
sarmod5 <- lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist4)
summary(sarmod5)
sermod5 <- errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist4)
summary(sermod5)
Hausman.test(sermod5)
sdmmod5 = lagsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist4, type='mixed')
summary(sdmmod5)
sdemmod5 = errorsarlm(regr_fm, ro_Vaccines_incidence_socioec_std, w_dist4, etype='emixed')
summary(sdemmod5)
LR.Sarlm(sdemmod5, sermod5)
LR.Sarlm(sdemmod5, slxmod5)
bptest.Sarlm(sdemmod5, studentize=TRUE)
1-(sdemmod5$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_May)*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)))
```

### Robusteness check - replacing the primary education with school enrollment
```{r}
regr_fm2 <- vaccR_May~pover+elder+sch_enrol+empl+migr_exp+vote+neoprot+living_spa+airp+cov_max+size+core_c+per_c+per_v
olsmod2 <- lm(regr_fm2, ro_Vaccines_incidence_socioec_std)
#lm.morantest(olsmod2, w_queen)
#lm.LMtests(olsmod2, w_queen, test='all')
slxmod_robust <- lmSLX(regr_fm2, ro_Vaccines_incidence_socioec_std, w_queen)
sarmod_robust <- lagsarlm(regr_fm2, ro_Vaccines_incidence_socioec_std, w_queen)
sermod_robust <- errorsarlm(regr_fm2, ro_Vaccines_incidence_socioec_std, w_queen)
#Hausman.test(sermod_robust)
sdmmod_robust = lagsarlm(regr_fm2, ro_Vaccines_incidence_socioec_std, w_queen, type='mixed')
sdemmod_robust = errorsarlm(regr_fm2, ro_Vaccines_incidence_socioec_std, w_queen, etype='emixed')
summary(sdemmod_robust)
LR.Sarlm(sdemmod_robust, sermod_robust)
LR.Sarlm(sdemmod_robust, slxmod_robust)
bptest.Sarlm(sdemmod_robust, studentize=TRUE)
1-(sdemmod_robust$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_May)*(length(ro_Vaccines_incidence_socioec_std$vaccR_May)-1)))
```
```{r}
summary(impacts(sdemmod_robust, listw=w_queen), zstats=TRUE)
```

Tidy coefficients and automatically write a csv file with them:
```{r}
tidy_sdem_robust <- tidy(sdemmod_robust)
write.csv(tidy_sdem_robust, "data/tidy_sdemmod_robust.csv")
```

### Rerun all models using vaccination rate in Oct
```{r}
regr_fm3t <- vaccR_Oct~pover+elder+prim_edu+empl+migr_exp+vote+neoprot+living_spa+airp+cov_max+size+core_c+per_c+per_v
olsmod3 <- lm(regr_fm3t, ro_Vaccines_incidence_socioec_std)
lm.morantest(olsmod3, w_queen)
lm.LMtests(olsmod3, w_queen, test='all')
slxmod_oct <- lmSLX(regr_fm3t, ro_Vaccines_incidence_socioec_std, w_queen)
sarmod_oct <- lagsarlm(regr_fm3t, ro_Vaccines_incidence_socioec_std, w_queen)
sermod_oct <- errorsarlm(regr_fm3t, ro_Vaccines_incidence_socioec_std, w_queen)
Hausman.test(sermod_oct)
sdmmod_oct <- lagsarlm(regr_fm3t, ro_Vaccines_incidence_socioec_std, w_queen, type='mixed')
sdemmod_oct <- errorsarlm(regr_fm3t, ro_Vaccines_incidence_socioec_std, w_queen, etype='emixed')
LR.Sarlm(sdemmod_oct, sermod_oct)
LR.Sarlm(sdemmod_oct, slxmod_oct)
bptest.Sarlm(sdemmod_oct, studentize=TRUE)
1-(sdemmod_oct$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_Oct)*(length(ro_Vaccines_incidence_socioec_std$vaccR_Oct)-1)))
```
```{r}
summary(sdemmod_oct)
```

```{r}
1-(sdemmod_oct$SSE/(var(ro_Vaccines_incidence_socioec_std$vaccR_Oct)*(length(ro_Vaccines_incidence_socioec_std$vaccR_Oct)-1)))
```

```{r}
summary(impacts(sdemmod_oct, listw=w_queen), zstats=TRUE)
```

Tidy coefficients and automatically write a csv file with them:
```{r}
tidy_sdemmod_oct <- tidy(sdemmod_oct)
write.csv(tidy_sdemmod_oct, "data/tidy_sdemmod_oct.csv")
```